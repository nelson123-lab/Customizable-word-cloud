# word-cloud

A word cloud, also known as a tag cloud, is a visual representation of the most frequently used words in a given text or set of texts. The words are typically displayed in different sizes and font weights, with the most frequently used words being displayed in the largest font size. The goal of a word cloud is to quickly identify the most important or relevant words in a text, and it is often used as a way to summarize or analyze large amounts of text data. Word clouds can be created using various online tools or software programs.

Web scrapping is used here for generating word cloud. Web scraping is a technique for extracting information from websites. It can be used to gather the text data from a website, which can then be analyzed and used to create a word cloud.

Stemming is the process of reducing a word to its stem that affixes to suffixes and prefixes or to the roots of words known as "lemmas". Stemming is important in natural language understanding (NLU) and natural language processing (NLP).

Lemmatization is the process of reducing a word to its base form, also known as its lemma. This is different from stemming, which reduces words to their root form, but the resulting words may not be actual words.

For example, the word "running" would be stemmed to "run", but lemmatized to "run". The word "better" would be stemmed to "better", but lemmatized to "good".

Lemmatization is considered to be a more sophisticated method than stemming because it uses the context and part of speech of a word to determine its lemma. It is typically used in natural language processing tasks such as text classification, information retrieval, and machine translation.

There are many libraries available in various programming languages that can be used for lemmatization, such as NLTK in Python, and the Stanford CoreNLP library in Java.

It is important to notice that lemmatization process is based on a dictionary and sometimes it might be not able to lemmatize a word if it is not in the dictionary. Additionally, some words might have multiple lemmas based on their context, and the lemmatization process might not be able to determine the correct one.




